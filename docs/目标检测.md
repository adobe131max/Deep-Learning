# 目标检测 - Object Detection

## 基础知识

- anchor box                        锚框
- bounding box                      边界框
- IoU (Intersection over Union)     交并比
- NMS (Non-maximum suppression)     非极大值抑制，只保留和 ground truth 重叠度最高的 bounding box

## 评价指标

### AP (Average Precision)

- AP是PR曲线(Precision-Recall曲线)下的面积
- 对每个类别单独计算AP
- 通常使用不同IoU阈值(如0.5,0.75等)计算AP

### mAP (mean Average Precision)

- mAP是所有类别AP的平均值
- COCO数据集的mAP计算方式:
  - mAP@.5: IoU阈值为0.5时的mAP
  - mAP@.75: IoU阈值为0.75时的mAP
  - mAP@[.5:.95]: IoU从0.5到0.95,步长0.05,计算平均mAP

### FPS (Frames Per Second)

## 算法

### RCNN

算法流程：

1. 由图像使用Select Search方法生成多个候选区域
2. 使用深度神经网络对每个候选区域提取特征
3. 根据特征使用SVM分类
4. 使用回归器修正候选框位置

### Fast-RCNN

算法流程：

1. 由图像使用Select Search方法生成多个候选区域
2. 使用深度神经网络对整个图像生成特征图，并将候选区域投影到特征图上获得特征矩阵
3. 对每个特征矩阵通过ROI pooling缩放，再通过全连接得到预测结果

### Faster-RCNN

[参考详解](https://blog.csdn.net/weixin_42310154/article/details/119889682)

算法流程：

1. 图像输入网络得到特征图
2. 使用 RPN（Region Proposal Network） 生成候选框，将候选框投影到特征图上获得特征矩阵
3. 对每个特征矩阵通过ROI pooling缩放，再通过全连接得到预测结果

**结构详解：**

#### GeneralizedRCNNTransform

1. 对图像normalize
2. 缩放图像和bbox，每个图像按照长宽中小者缩放为min_size，如果长者缩放后大于max_size则将大者缩放为max_size
3. 合并为一个tensor，高宽为batch中每张图高宽的最大值并按size_divisible向上取整，空白用0填充
4. postprocess将预测结果还原到原尺度上

#### Backbone

特征提取，输出特征层：$M \times N$ → $(M/16)\times(N/16)$

#### RegionProposalNetwork

1. AnchorsGenerator:
   1. 为每个特征层生成anchor模板（不同面积与长宽比例）
   2. 为每个特征层将每个像素的坐标缩放到GeneralizedRCNNTransform输出的尺度上
   3. 每个像素的坐标与anchor模板相加，生成所有anchor
   4. 返回每张图像的所有anchor
2. RPNHead:
   1. 对每个特征层进行相同的3x3卷积
   2. 分别两个1x1卷积预测cls与bbox偏移
3. 使用修正参数调整anchor生成proposal
4. filter_proposals
   1. 为每张图像的每个特征层选择objectness前指定数量（2000）个box
   2. 调整越界box
   3. 删除过小box
   4. NMS（先把不同特征层的box加上一个很大的偏移量分开，以实现在不同特征层上分别nms）
5. Loss（是对所有的anchor而非筛选后的proposal）(注意loss与生成proposal和筛选proposal是无关的，并不是直接选择proposal计算loss，计算loss是为了让这些anchor成为proposal)
   1. 设置anchor正负样本与正样本对应的gt_box（注意这里是anchor，而不是修正后的proposal）
      1. 计算每个anchor和每个gtbox的iou
      2. iou大于0.7的anchor为正样本
      3. 与gtbox的iou最大的anchor为正样本
      4. iou小于0.3的anchor为负样本
   2. 计算从anchor到gtbox的真实回归参数
   3. 计算loss（只选择部分正负样本参与计算loss，只有正样本参与计算回归参数loss）

#### ROIHeads

1. 训练模式划分正负样本并继续采样 proposal
2. ROI pooling 将 proposal 映射的特征矩阵缩放到7x7
3. 使用两个全连接处理
4. 再各使用一个全连接输出每类的概率和每类的回归参数
5. 训练模式计算loss
6. 推理模式后处理
   1. 每个proposal每个类别修正的bbox都保留，只删除背景的bbox
   2. 删除概率小于 0.05 的bbox
   3. 删除小目标
   4. 对每个类别进行nms处理，返回前topk个目标

**个人理解：**

1. 为什么要划分正负样本？
   1. 负样本只需要计算分类损失；
   2. target只有gtbox，预测的bbox没有真实标签，没法计算loss，划分正负样本就是在修正前告诉它对应的分类和gtbox
2. 为什么要对正负样本采样？
   平衡loss，防止负样本太多使得分类loss占比过大

**潜在问题：**

1. 为什么只输入proposal对应的特征矩阵预测回归参数？
   感觉如果proposal不包括完整的gtbox的话很难预测回归参数，输入的特征矩阵应该比proposal大才合理

---

### SSD (Single Shot MultiBox Detector)

one stage，不像faster-rcnn需要two stages(先proposal再分类回归)，其实就是在rpn时直接一步到位（分类+回归），不再对proposal进行roi

在低层特征层上预测小目标，高层特征层预测大目标

1. 依次生成多个特征层，特征层的hw越来越小，生成的default box尺寸越来越大
2. 对不同特征层的每个像素生成不同尺度和长宽比的default box
3. 使用3x3卷积对特征层每个像素预测 $(c + 4) \times k$ 个参数，k为每个像素生成的default box数量，c为类别数，也就是对每个default box预测四个偏移量与c个类别（包含背景类别）
4. 选取正负样本，正样本选取类似faster-rcnn，其余为负样本，但只选择预测为正样本概率最高的那部分

### Mask-RCNN

---

### YOLO (You Only Look Once)

#### YOLO v1

在7x7的grid cell上预测两个bounding box的confidence、xywh回归值和类别概率

#### YOLO v2

#### YOLO v3

---

### DETR

### FPN - Feature Pyramid Networks

## 数据集

### PASCAL VOC

本地路径：D:\Dataset\VOCtrainval_11-May-2012

``` plain
VOCdevkit
    └── VOC2012
         ├── Annotations               所有的图像标注信息(XML文件)
         ├── ImageSets    
         │   ├── Action                人的行为动作图像信息
         │   ├── Layout                人的各个部位图像信息
         │   │
         │   ├── Main                  目标检测分类图像信息
         │   │     ├── train.txt       训练集(5717)
         │   │     ├── val.txt         验证集(5823)
         │   │     └── trainval.txt    训练集+验证集(11540)
         │   │
         │   └── Segmentation          目标分割图像信息
         │         ├── train.txt       训练集(1464)
         │         ├── val.txt         验证集(1449)
         │         └── trainval.txt    训练集+验证集(2913)
         │ 
         ├── JPEGImages                所有图像文件
         ├── SegmentationClass         语义分割png图（基于类别）
         └── SegmentationObject        实例分割png图（基于目标）
```

### MS COCO
